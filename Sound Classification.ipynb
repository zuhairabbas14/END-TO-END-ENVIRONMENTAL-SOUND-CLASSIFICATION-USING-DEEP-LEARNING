{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "FINAL Copy of Sound Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "aUqJT1RCIMGI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install pydub\n",
        "\n",
        "import pandas as pd\n",
        "import os\n",
        "import librosa\n",
        "import librosa.display\n",
        "from PIL import Image\n",
        "import shutil\n",
        "from pydub import AudioSegment\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "# import librosa.display\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "import csv\n",
        "# from skimage.feature  import hog, local_binary_pattern\n",
        "import scipy.io.wavfile \n",
        "from six.moves import cPickle as pickle\n",
        "from math import sqrt\n",
        "from numpy import split\n",
        "from google.colab.patches import cv2_imshow\n",
        "from numpy import array\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from pandas import read_csv\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from matplotlib import pyplot\n",
        "import tensorflow\n",
        "from keras.applications import vgg16 as vgg_model\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.models import Sequential\n",
        "from keras import optimizers\n",
        "from keras.layers import Dense\n",
        "from keras.initializers import RandomNormal\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import LSTM, Dropout\n",
        "from keras.layers.core import Dense, Dropout, Activation, Flatten, Reshape\n",
        "from keras.layers import RepeatVector\n",
        "from keras.optimizers import SGD, Adam\n",
        "from keras.layers import TimeDistributed\n",
        "from keras.layers.convolutional import Conv1D\n",
        "from keras.layers.convolutional import MaxPooling1D\n",
        "from keras.layers.pooling import GlobalAveragePooling2D\n",
        "from keras.layers import Input, Dense, LSTM, MaxPooling1D, Conv1D\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D, ZeroPadding2D\n",
        "from keras.models import Sequential, Model, load_model\n",
        "from keras import applications\n",
        "from keras import optimizers\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.layers import LSTM\n",
        "from keras.utils.io_utils import HDF5Matrix\n",
        "import h5py\n",
        "# from models.my_callbacks import *\n",
        "import time\n",
        "\n",
        "# import tensorflow as tf\n",
        "# tf.test.gpu_device_name()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V3-QQeN5BqlY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "097fBzoukXq1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "## TRAIN DATA FROM PICKLE FILE\n",
        "\n",
        "data_file = '/content/gdrive/My Drive/contrast4_no_segments_train.pickle' # redefined varaible in case you have completed above steps previously.\n",
        "print('Tring to load pickle from %s' % data_file)\n",
        "\n",
        "with open(data_file, 'rb') as file:\n",
        "  \n",
        "    svhn_datasets = pickle.load(file)\n",
        "    train_dataset_contrast = svhn_datasets['train_dataset']\n",
        "    del svhn_datasets\n",
        "    \n",
        "print('Pickle Loaded Successfully!')\n",
        "\n",
        "## TEST DATA FROM PICKLE FILE\n",
        "\n",
        "data_file = '/content/gdrive/My Drive/contrast4_no_segments_test.pickle' # redefined varaible in case you have completed above steps previously.\n",
        "print('Tring to load pickle from %s' % data_file)\n",
        "\n",
        "with open(data_file, 'rb') as file:\n",
        "  \n",
        "    svhn_datasets = pickle.load(file)\n",
        "    test_dataset_contrast = svhn_datasets['test_dataset']\n",
        "    del svhn_datasets\n",
        "    \n",
        "print('Pickle Loaded Successfully!')\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lDZRnR19W-vu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def split_dataset(data, labels):\n",
        "    \n",
        "    x_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=0.2, random_state=0)\n",
        "    return x_train, x_test, y_train, y_test\n",
        "\n",
        "  \n",
        "# def build_model(dropout, optimizer,lr):   # [FOR GRID SEARCH]\n",
        " \n",
        "# train the model\n",
        "def build_model(x_train, y_train, x_test, y_test, dropout):\n",
        "    \n",
        "#     print(\"------>> \" + str(dropout) + \",\" + str(lr) + \",\" + str(optimizer) + \" <<------\")\n",
        "    \n",
        "    # define parameters\n",
        "    num_rows = x_train.shape[1]\n",
        "    num_columns = 775\n",
        "    num_channels = 1\n",
        "\n",
        "    num_labels = 10\n",
        "    filter_size = 2\n",
        "\n",
        "    # Construct model \n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(filters=16, kernel_size=2, input_shape=(num_rows, num_columns, num_channels), activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "#     model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(filters=32, kernel_size=2, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "#     model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(filters=64, kernel_size=2, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "#     model.add(Dropout(0.2))\n",
        "\n",
        "    model.add(Conv2D(filters=128, kernel_size=2, activation='relu'))\n",
        "    model.add(MaxPooling2D(pool_size=2))\n",
        "#     model.add(Dropout(0.2))\n",
        "#     model.add(GlobalAveragePooling2D())\n",
        "\n",
        "    model.add(Dropout(dropout))\n",
        "    model.add(Flatten())\n",
        "    model.add(Dense(128, activation='relu'))\n",
        "    model.add(Dense(64, activation='relu'))\n",
        "\n",
        "    model.add(Dense(num_labels, activation='softmax'))\n",
        "    \n",
        "    print(model.summary())\n",
        "    \n",
        "    return model\n",
        "  \n",
        "\n",
        "def acc(y_true, y_pred):\n",
        "    return np.equal(np.argmax(y_true, axis=-1), np.argmax(y_pred, axis=-1)).mean()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGpWjXZOT1Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train_mfcc = train_dataset_mfcc['X']\n",
        "y_train_mfcc = train_dataset_mfcc['y']\n",
        "x_test_mfcc = test_dataset_mfcc['X']\n",
        "y_test_mfcc = test_dataset_mfcc['y']\n",
        "\n",
        "x_train_centroid = train_dataset_centroid['X']\n",
        "y_train_centroid = train_dataset_centroid['y']\n",
        "x_test_centroid = test_dataset_centroid['X']\n",
        "y_test_centroid = test_dataset_centroid['y']\n",
        "\n",
        "x_train_cens = train_dataset_cens['X']\n",
        "y_train_cens = train_dataset_cens['y']\n",
        "x_test_cens = test_dataset_cens['X']\n",
        "y_test_cens = test_dataset_cens['y']\n",
        "\n",
        "x_train_contrast = train_dataset_contrast['X']\n",
        "y_train_contrast = train_dataset_contrast['y']\n",
        "x_test_contrast = test_dataset_contrast['X']\n",
        "y_test_contrast = test_dataset_contrast['y']\n",
        "\n",
        "del train_dataset_mfcc\n",
        "del train_dataset_centroid\n",
        "del train_dataset_contrast\n",
        "del train_dataset_cens\n",
        "\n",
        "print(x_train_mfcc.shape)\n",
        "print(y_train_mfcc.shape)\n",
        "print(x_test_mfcc.shape)\n",
        "print(y_test_mfcc.shape)\n",
        "print('\\n\\n')\n",
        "\n",
        "print(x_train_cens.shape)\n",
        "print(y_train_cens.shape)\n",
        "print(x_test_cens.shape)\n",
        "print(y_test_cens.shape)\n",
        "print('\\n\\n')\n",
        "\n",
        "print(x_train_centroid.shape)\n",
        "print(y_train_centroid.shape)\n",
        "print(x_test_centroid.shape)\n",
        "print(y_test_centroid.shape)\n",
        "print('\\n\\n')\n",
        "\n",
        "print(x_train_contrast.shape)\n",
        "print(y_train_contrast.shape)\n",
        "print(x_test_contrast.shape)\n",
        "print(y_test_contrast.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nklviUhMRO3u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = np.concatenate((x_train_mfcc, x_train_cens, x_train_centroid, x_train_contrast), axis=1)\n",
        "x_test = np.concatenate((x_test_mfcc, x_test_cens, x_test_centroid, x_test_contrast), axis=1)\n",
        "y_train = y_train_mfcc\n",
        "y_test = y_test_mfcc\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eC896S2N7dU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], 775, 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], 775, 1)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0lfZzgJgHB4q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.3, random_state=0)\n",
        "\n",
        "print(x_train.shape)\n",
        "print(y_train.shape)\n",
        "\n",
        "print(x_test.shape)\n",
        "print(y_test.shape)\n",
        "\n",
        "print(x_val.shape)\n",
        "print(y_val.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dlyLKh7G2wkv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dropout = 0.3\n",
        "model = build_model(x_train, y_train, x_test, y_test, dropout)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRx5bkP_2x6I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.optimizers import Nadam\n",
        "optimizer = Nadam(lr=0.0005,\n",
        "                  beta_1=0.9,\n",
        "                  beta_2=0.999,\n",
        "                  epsilon=1e-08,\n",
        "                  schedule_decay=0.004)\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
        "              optimizer=optimizer,\n",
        "              metrics=[\"accuracy\"]) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4pCciCzG20dT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "verbose, epochs, batch_size = 1, 20, 32\n",
        "history = model.fit(x_train, y_train, epochs=epochs, batch_size=batch_size, verbose=verbose, validation_data= (x_test, y_test))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Lx6kk3qU73Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(history.history['acc'])\n",
        "plt.plot(history.history['val_acc'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "fig1 = plt.gcf()\n",
        "plt.show()\n",
        "# fig1.savefig('model_accuracy_ECN2.png', dpi=100)\n",
        "\n",
        "# summarize history for loss\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "fig2 = plt.gcf()\n",
        "plt.show()\n",
        "# fig2.savefig('model_loss_ECN2.png', dpi=100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rplfiBlDQyhM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import load_model\n",
        "# model.save('my_model.h5')  \n",
        "\n",
        "model = load_model('/content/gdrive/My Drive/my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "drnT0fL50V21",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('⦁\tMECN\t⦁\\n\\n')\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print(\"Test Accuracy All: \", score[1])\n",
        "print('\\n')\n",
        "\n",
        "for i in range(10):\n",
        "  score = model.evaluate(x_test[np.where(y_test==i)], y_test[np.where(y_test==i)], verbose=0)\n",
        "  print('Testing Accuracy_' + str(i) + ': ', score[1])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GY_tzYB_xQKa",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    }
  ]
}